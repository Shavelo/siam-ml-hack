{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бейзлайн модель для обнаружения паттернов КВД и КПД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфигурация\n",
    "DATA_PATH = \"../data/raw/\"\n",
    "WINDOW_SIZE = 50  # точек в окне\n",
    "STEP = 10         # шаг окна\n",
    "MIN_DURATION = 4  # часов для recovery\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Загрузка данных и разметки\n",
    "# ---------------------------------------------------\n",
    "def load_data(file_id, is_test=False):\n",
    "    \"\"\"Загрузка временного ряда по ID файла\"\"\"\n",
    "    # Определяем путь в зависимости от типа данных\n",
    "    folder = \"test\" if is_test else \"Task 21\"\n",
    "    path = os.path.join(DATA_PATH, folder, file_id)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Файл {file_id} не найден в папке {folder}.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(path, sep='\\t', header=None, names=['time', 'pressure'])\n",
    "    return df.sort_values('time').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Предобработка данных\n",
    "# ---------------------------------------------------\n",
    "def preprocess_series(df):\n",
    "    \"\"\"Сглаживание и нормализация\"\"\"\n",
    "    df['pressure'] = df['pressure'].rolling(5, center=True, min_periods=1).mean()\n",
    "    df['pressure'] = (df['pressure'] - df['pressure'].min()) / \\\n",
    "                    (df['pressure'].max() - df['pressure'].min())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Генерация признаков для окон\n",
    "# ---------------------------------------------------\n",
    "def get_window_features(window):\n",
    "    \"\"\"Извлечение признаков из окна\"\"\"\n",
    "    time = window['time'].values\n",
    "    pressure = window['pressure'].values\n",
    "    \n",
    "    features = {\n",
    "        'slope': np.polyfit(time, pressure, 1)[0],\n",
    "        'mean': np.mean(pressure),\n",
    "        'std': np.std(pressure),\n",
    "        'max_diff': np.max(pressure) - np.min(pressure),\n",
    "        'duration': time[-1] - time[0]\n",
    "    }\n",
    "    return pd.Series(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Подготовка датасета для обучения\n",
    "# ---------------------------------------------------\n",
    "def create_dataset(file_ids, gt):\n",
    "    \"\"\"Создание размеченного датасета с проверкой существования файлов\"\"\"\n",
    "    features = []\n",
    "    targets = []\n",
    "    \n",
    "    # Проверка наличия файлов в Task 21\n",
    "    valid_files = []\n",
    "    for file_id in file_ids:\n",
    "        path = os.path.join(DATA_PATH, \"Task 21\", file_id)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Файл {file_id} из разметки отсутствует в Task 21 и будет пропущен.\")\n",
    "        else:\n",
    "            valid_files.append(file_id)\n",
    "    \n",
    "    # Обработка только валидных файлов\n",
    "    for file_id in tqdm(valid_files):\n",
    "        df = load_data(file_id, is_test=False)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        df = preprocess_series(df)\n",
    "        \n",
    "        # Получение разметки для файла\n",
    "        file_gt = gt[gt['file'] == file_id].iloc[0]\n",
    "        recovery = eval(file_gt['recovery'])\n",
    "        drop = eval(file_gt['drop'])\n",
    "        \n",
    "        # Скользящее окно\n",
    "        for i in range(0, len(df)-WINDOW_SIZE, STEP):\n",
    "            window = df.iloc[i:i+WINDOW_SIZE]\n",
    "            window_features = get_window_features(window)\n",
    "            \n",
    "            # Проверка попадания в разметку\n",
    "            target = 0\n",
    "            start = window['time'].iloc[0]\n",
    "            end = window['time'].iloc[-1]\n",
    "            \n",
    "            for interval in recovery:\n",
    "                if interval[0] <= start and end <= interval[1]:\n",
    "                    target = 1  # recovery\n",
    "            for interval in drop:\n",
    "                if interval[0] <= start and end <= interval[1]:\n",
    "                    target = 2  # drop\n",
    "                    \n",
    "            features.append(window_features)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return pd.DataFrame(features), np.array(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание датасета\n",
    "gt = pd.read_csv(os.path.join(DATA_PATH, \"ground_truth.csv\"))\n",
    "train_files = gt['file']\n",
    "X, y = create_dataset(train_files, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 5. Обучение модели с кросс-валидацией\n",
    "# ---------------------------------------------------\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Настройки модели\n",
    "model_params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 7,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'class_weights': [1, 10, 10],  # [фон, recovery, drop]\n",
    "    'task_type': 'CPU',  # Для GPU: 'GPU'\n",
    "    'verbose': 200\n",
    "}\n",
    "\n",
    "# Кросс-валидация\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = CatBoostClassifier(**model_params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "    \n",
    "    # Прогноз и метрики\n",
    "    y_pred = model.predict(X_val)\n",
    "    results.append(classification_report(y_val, y_pred, target_names=['background', 'recovery', 'drop']))\n",
    "\n",
    "# Вывод метрик\n",
    "for i, report in enumerate(results):\n",
    "    print(f\"Fold {i+1}:\\n{report}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. Предсказание и постобработка\n",
    "# ---------------------------------------------------\n",
    "def predict_intervals(model, file_id, is_test=False):\n",
    "    \"\"\"Предсказание интервалов для одного файла\"\"\"\n",
    "    df = load_data(file_id, is_test=is_test)\n",
    "    if df is None:\n",
    "        return {'recovery': [], 'drop': []}\n",
    "    \n",
    "    df = preprocess_series(df)\n",
    "    \n",
    "    # Прогноз для всего ряда\n",
    "    window_preds = []\n",
    "    for i in range(0, len(df)-WINDOW_SIZE, STEP):\n",
    "        window = df.iloc[i:i+WINDOW_SIZE]\n",
    "        features = get_window_features(window)\n",
    "        pred = model.predict(pd.DataFrame([features]))[0]\n",
    "        window_preds.append( (window['time'].iloc[0], window['time'].iloc[-1], pred) )\n",
    "    \n",
    "    # Объединение интервалов\n",
    "    merged = []\n",
    "    current = None\n",
    "    for start, end, label in window_preds:\n",
    "        if label == 0:\n",
    "            continue\n",
    "        if current and current[2] == label and current[1] >= start - 1:\n",
    "            current = (current[0], end, label)\n",
    "        else:\n",
    "            if current:\n",
    "                merged.append(current)\n",
    "            current = (start, end, label)\n",
    "    if current:\n",
    "        merged.append(current)\n",
    "    \n",
    "    # Фильтрация по длительности\n",
    "    filtered = []\n",
    "    for interval in merged:\n",
    "        duration = interval[1] - interval[0]\n",
    "        if duration >= MIN_DURATION:\n",
    "            filtered.append(interval)\n",
    "    \n",
    "    # Форматирование результата\n",
    "    result = {'recovery': [], 'drop': []}\n",
    "    for start, end, label in filtered:\n",
    "        if label == 1:  # recovery\n",
    "            result['recovery'].append([start, end])\n",
    "        elif label == 2:  # drop\n",
    "            result['drop'].append([start, end])\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------\n",
    "# 7. Визуализация результатов\n",
    "# ---------------------------------------------------\n",
    "def plot_comparison(file_id, pred_intervals, gt_entry):\n",
    "    \"\"\"\n",
    "    Визуализация предсказаний и истинных интервалов.\n",
    "    \n",
    "    :param file_id: ID файла (строка).\n",
    "    :param pred_intervals: Предсказанные интервалы (словарь с ключами 'recovery' и 'drop').\n",
    "    :param gt_entry: Строка из ground_truth.csv с истинными интервалами.\n",
    "    \"\"\"\n",
    "    # Загрузка данных\n",
    "    df = load_data(file_id)\n",
    "    if df is None:\n",
    "        print(f\"Файл {file_id} не найден.\")\n",
    "        return\n",
    "    \n",
    "    # Создание двух графиков\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "    \n",
    "    # График 1: Предсказанные интервалы\n",
    "    ax1.plot(df['time'], df['pressure'], label='Давление', color='blue')\n",
    "    \n",
    "    # Предсказанные recovery\n",
    "    for interval in pred_intervals['recovery']:\n",
    "        start, end = interval\n",
    "        ax1.axvspan(start, end, alpha=0.2, color='green')\n",
    "    \n",
    "    # Предсказанные drop\n",
    "    for interval in pred_intervals['drop']:\n",
    "        start, end = interval\n",
    "        ax1.axvspan(start, end, alpha=0.2, color='red')\n",
    "    \n",
    "    ax1.set_title(f\"Предсказанные интервалы для {file_id}\")\n",
    "    ax1.set_ylabel(\"Нормализованное давление\")\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # График 2: Истинные интервалы\n",
    "    ax2.plot(df['time'], df['pressure'], label='Давление', color='blue')\n",
    "    \n",
    "    # Истинные recovery\n",
    "    for interval in eval(gt_entry['recovery']):\n",
    "        ax2.axvspan(interval[0], interval[1], alpha=0.2, color='green', label='True Recovery')\n",
    "    \n",
    "    # Истинные drop\n",
    "    for interval in eval(gt_entry['drop']):\n",
    "        ax2.axvspan(interval[0], interval[1], alpha=0.2, color='red', label='True Drop')\n",
    "    \n",
    "    ax2.set_title(f\"Истинные интервалы для {file_id}\")\n",
    "    ax2.set_xlabel(\"Время (часы)\")\n",
    "    ax2.set_ylabel(\"Нормализованное давление\")\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Удаление дубликатов в легенде\n",
    "    handles, labels = ax2.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax2.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Пример использования\n",
    "test_file = gt['file'].iloc[0]\n",
    "predicted = predict_intervals(model, test_file)\n",
    "gt_entry = gt[gt['file'] == test_file].iloc[0]\n",
    "plot_comparison(test_file, predicted, gt_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------\n",
    "# 8. Генерация сабмита\n",
    "# ---------------------------------------------------\n",
    "def generate_submission(model, test_files, output_path):\n",
    "    \"\"\"Генерация файла для отправки на платформу\"\"\"\n",
    "    submission = []\n",
    "    \n",
    "    for file_path in tqdm(test_files):\n",
    "        # Извлекаем только имя файла без пути\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        # Предсказание с флагом is_test=True\n",
    "        preds = predict_intervals(model, file_name, is_test=True)\n",
    "        \n",
    "        submission.append({\n",
    "            'file': file_name,\n",
    "            'recovery': str(preds['recovery']).replace(' ', ''),\n",
    "            'drop': str(preds['drop']).replace(' ', '')\n",
    "        })\n",
    "    \n",
    "    # Сохранение в CSV\n",
    "    pd.DataFrame(submission).to_csv(output_path, index=False)\n",
    "    print(f\"Сабмит сохранен в {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к тестовым данным\n",
    "TEST_PATH = os.path.join(DATA_PATH, \"test\")\n",
    "\n",
    "# Получаем список всех файлов в тестовой папке\n",
    "test_files = [os.path.join(TEST_PATH, f) for f in os.listdir(TEST_PATH) \n",
    "              if os.path.isfile(os.path.join(TEST_PATH, f))]\n",
    "\n",
    "# Генерация сабмита\n",
    "generate_submission(\n",
    "    model=model,\n",
    "    test_files=test_files,\n",
    "    output_path=\"../data/submissions/submission1.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
